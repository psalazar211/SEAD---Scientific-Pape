{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lenet 5 con MNIST\n",
        "Charge Dataset"
      ],
      "metadata": {
        "id": "oxYC2bnSriVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "DV3qfFjwu5Xm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import data\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "batch_size = 1000\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root='./data', train=False, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for data, label in test_loader:\n",
        "    break\n",
        "data, label = data, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6qsezYtvAZH",
        "outputId": "1836ec61-17d7-4a3e-bd50-2e4c993f3603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 399701118.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 106821599.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 151365537.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3562178.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approximate floating point multiplier (Ax-FPM)"
      ],
      "metadata": {
        "id": "UM4fJtdIvBjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Approximate 4x4 array multiplier (using the approximate mirror adder AMA5)\n",
        "def appx_multiplier4x4_AMA5(A,B):\n",
        "\n",
        "    S = 0\n",
        "    if (A == 0) or (B == 0):\n",
        "        S = 0\n",
        "    elif (A == 1):\n",
        "        S = B\n",
        "    elif (A % 2 == 0) & (A>1):\n",
        "        if (B < 8):\n",
        "            S = 0\n",
        "        else:\n",
        "            S = 32 * (A/2)\n",
        "    else:\n",
        "        if (B < 8):\n",
        "            S = B\n",
        "        else:\n",
        "            S = B + 32 * (A-1)/2\n",
        "    return S"
      ],
      "metadata": {
        "id": "tsJuL9Y5vnKO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Approximate 8x8 array multiplier\n",
        "def appx_multiplier8x8(a,b):\n",
        "\n",
        "    a0b0 = appx_multiplier4x4_AMA5(int(a[4:8],2), int(b[4:8],2))\n",
        "    a1b0 = appx_multiplier4x4_AMA5(int(a[0:4],2), int(b[4:8],2))\n",
        "    a0b1 = appx_multiplier4x4_AMA5(int(a[4:8],2), int(b[0:4],2))\n",
        "    a1b1 = appx_multiplier4x4_AMA5(int(a[0:4],2), int(b[0:4],2))\n",
        "    S = (a0b0 + (a1b0 + a0b1)*16 + a1b1*256)\n",
        "    S = format(int(S), '016b')\n",
        "    return S"
      ],
      "metadata": {
        "id": "QkkWeAbdvvo0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Approximate 24x24 array multiplier\n",
        "def appx_multiplier24x24(a,b):\n",
        "    a0 = a[16:24]\n",
        "    a1 = a[8:16]\n",
        "    a2 = a[0:8]\n",
        "    b0 = b[16:24]\n",
        "    b1 = b[8:16]\n",
        "    b2 = b[0:8]\n",
        "\n",
        "    a0b0 = int(appx_multiplier8x8(a0,b0),2)\n",
        "    a1b0 = int(appx_multiplier8x8(a1,b0),2)*256\n",
        "    a2b0 = int(appx_multiplier8x8(a2,b0),2)*256*256\n",
        "    a0b1 = int(appx_multiplier8x8(a0,b1),2)*256\n",
        "    a1b1 = int(appx_multiplier8x8(a1,b1),2)*256*256\n",
        "    a2b1 = int(appx_multiplier8x8(a2,b1),2)*256*256*256\n",
        "    a0b2 = int(appx_multiplier8x8(a0,b2),2)*256*256\n",
        "    a1b2 = int(appx_multiplier8x8(a1,b2),2)*256*256*256\n",
        "    a2b2 = int(appx_multiplier8x8(a2,b2),2)*256*256*256*256\n",
        "\n",
        "    S = a0b0 + a1b0 + a2b0 + a0b1 + a1b1 + a2b1 + a0b2 + a1b2 + a2b2\n",
        "    S = format(S, '048b')\n",
        "    #print(S)\n",
        "\n",
        "    return S"
      ],
      "metadata": {
        "id": "KxiyjN98vz_-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Decimal number to Floating Point number\n",
        "import struct\n",
        "def dec2FP(num):\n",
        "    s = ''.join(bin(c).replace('0b', '').rjust(8, '0') for c in struct.pack('!f', num))\n",
        "    return s"
      ],
      "metadata": {
        "id": "Gl_1bzQ5v7bO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Floating Point number to Decimal number\n",
        "def FP2dec(n):\n",
        "    #add subnormal numbers, for NaNs, for +/- infinity\n",
        "    s = struct.unpack('!f',struct.pack('!I', int(n, 2)))[0]\n",
        "    return s"
      ],
      "metadata": {
        "id": "b9ZJ9qDNwGAI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Approximate Floating Point multiplier\n",
        "def FP_appx_mul(A,B):\n",
        "    if (abs(A)<1e-36) or (abs(B)<1e-36) or (A == 0) or (B==0):\n",
        "        s = 0\n",
        "    else:\n",
        "        S = ['0','00000000','00000000000000000000000']\n",
        "        a = dec2FP(A)\n",
        "        b = dec2FP(B)\n",
        "        sign_ab = int(a[0])^int(b[0])\n",
        "        exponent_a = a[1:9]\n",
        "        if int(exponent_a,2)>255:\n",
        "            exponent_a = 255\n",
        "        exponent_b = b[1:9]\n",
        "        if int(exponent_a,2)>255:\n",
        "            exponent_b = 255\n",
        "        exponent_ab = int(exponent_a,2) + int(exponent_b,2) - 127\n",
        "        if exponent_ab>255:\n",
        "            exponent_ab = 255\n",
        "        mantissa_ab = appx_multiplier24x24('1'+ a[9:32],'1'+ b[9:32])\n",
        "        if mantissa_ab[0] == '1':\n",
        "            final_mantissa = mantissa_ab[1:24]\n",
        "            exponent_ab = exponent_ab + 1\n",
        "        else:\n",
        "            final_mantissa = mantissa_ab[2:25]\n",
        "        S = [str(sign_ab), format(exponent_ab,'08b'), final_mantissa]\n",
        "        S = ''.join(S)\n",
        "        s = FP2dec(S)\n",
        "    return s"
      ],
      "metadata": {
        "id": "_zooZUWYwJbz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approximate Convolution Layer (accelerated using Joblib Parallel)"
      ],
      "metadata": {
        "id": "tt7eBnuuw29k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class convAppx(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, X, weight, bias, padding, stride):\n",
        "        #confs = torch.from_numpy(np.array([stride[0], padding[0]]))\n",
        "\n",
        "        ctx.save_for_backward(X, weight, bias)\n",
        "        (m, n_C_prev, n_H_prev, n_W_prev) = X.shape\n",
        "        (n_C, n_C_prev, f, f) = weight.shape\n",
        "\n",
        "        n_H = ((n_H_prev - f + 2 * padding[0]) // stride[0]) + 1\n",
        "        n_W = ((n_W_prev - f + 2 * padding[0]) // stride[0]) + 1\n",
        "\n",
        "        def appx_mul(A,B):\n",
        "            window = np.zeros((A.shape))\n",
        "            for l in range(A.shape[0]):\n",
        "              for j in range(A.shape[1]):\n",
        "                for k in range(A.shape[2]):\n",
        "                  window[l,j,k] = FP_appx_mul(A[l,j,k],B[l,j,k])  #A[l,j,k]*B[l,j,k]\n",
        "            return np.sum(window)\n",
        "\n",
        "        def mul_channel( weight,bias, x_pad, n_H, n_W,f):\n",
        "              Z = np.zeros(( n_H, n_W ))\n",
        "              for h in range(n_H):\n",
        "                  for w in range(n_W):\n",
        "                      vert_start = h\n",
        "                      vert_end = vert_start + f\n",
        "                      horiz_start = w\n",
        "                      horiz_end = horiz_start + f\n",
        "\n",
        "                      x_slice = x_pad[:, vert_start:vert_end, horiz_start:horiz_end]\n",
        "                      Z[ h, w] = appx_mul(x_slice,weight)  #torch.matmul(A,B)\n",
        "                      Z[ h, w] += bias\n",
        "              return Z\n",
        "\n",
        "        X_pad = F.pad(X, (padding[0],padding[0],padding[0],padding[0]))\n",
        "        weight = weight.data.numpy()\n",
        "        bias = bias.data.numpy()\n",
        "        X_pad = X_pad.data.numpy()\n",
        "\n",
        "        Z = np.zeros((m, n_C, n_H, n_W ))\n",
        "\n",
        "        for i in range(m):\n",
        "          #for c in range(n_C):\n",
        "            #Z[i,c] = mul_channel( weight[c, :, :, :],bias[c], X_pad[0], n_H, n_W, f)\n",
        "            #x_pad = X[0]\n",
        "            Z[0] = Parallel(n_jobs=8)(delayed(mul_channel)( weight[c, :, :, :],bias[c], X_pad[0], n_H, n_W, f)  for c in  range(n_C) )\n",
        "        #print(\"forward\")\n",
        "        return torch.from_numpy(Z).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, weight, bias = ctx.saved_tensors\n",
        "\n",
        "        grad_input = grad_weight = grad_bias = None\n",
        "\n",
        "        def convolutionBackward(dconv_prev, conv_in, weight, padding =1, stride=1):\n",
        "            (m, n_C_prev, n_H_prev, n_W_prev) = conv_in.shape\n",
        "            (n_C, n_C_prev, f, f) = weight.shape\n",
        "            (m, n_C, n_H, n_W) = dconv_prev.shape\n",
        "\n",
        "            dA_prev = torch.zeros((m, n_C_prev, n_H_prev, n_W_prev))\n",
        "            dW = torch.zeros((n_C, n_C_prev, f, f))\n",
        "            db = torch.zeros((n_C))\n",
        "            X_pad = F.pad(conv_in, (padding,padding,padding,padding))\n",
        "            dA_prev_pad = F.pad(dA_prev, (padding,padding,padding,padding))\n",
        "\n",
        "            for i in range(m):\n",
        "                x_pad = X_pad[i]\n",
        "                da_prev_pad = dA_prev_pad[i]\n",
        "\n",
        "                for c in range(n_C):\n",
        "                    for h in range(n_H):\n",
        "                        for w in range(n_W):\n",
        "                            vert_start = h + h * (stride - 1)\n",
        "                            vert_end = vert_start + f\n",
        "                            horiz_start = w + w * (stride - 1)\n",
        "                            horiz_end = horiz_start + f\n",
        "\n",
        "                            x_slice = x_pad[:, vert_start:vert_end, horiz_start:horiz_end]\n",
        "\n",
        "                            da_prev_pad[:, vert_start:vert_end, horiz_start:horiz_end] += weight[c, :, :, :] * dconv_prev[i, c, h, w]\n",
        "\n",
        "                            dW[c,:,:,:] += x_slice * dconv_prev[i, c, h, w]\n",
        "\n",
        "                            db[c] += dconv_prev[i, c, h, w]\n",
        "                if padding == 0:\n",
        "                  dA_prev[i, :, :, :] = da_prev_pad[:]\n",
        "                else:\n",
        "                  dA_prev[i, :, :, :] = da_prev_pad[:, padding:-padding, padding:-padding]\n",
        "\n",
        "            return dA_prev, dW, db\n",
        "\n",
        "        grad_input, grad_weight, grad_bias = convolutionBackward(grad_output, x, weight)\n",
        "        grad_bias = grad_bias.squeeze()\n",
        "        #print(\"Backward!\")\n",
        "        return grad_input, grad_weight, grad_bias, None,None\n",
        "\n",
        "class MyConv2d(nn.Module):\n",
        "    def __init__(self, n_channels, out_channels, kernel_size , padding, stride, dilation=1):\n",
        "        super(MyConv2d, self).__init__()\n",
        "\n",
        "        self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.kernal_size_number = kernel_size * kernel_size\n",
        "        self.out_channels = out_channels\n",
        "        self.dilation = (dilation, dilation)\n",
        "        self.padding = (padding, padding)\n",
        "        self.stride = (stride, stride)\n",
        "        self.n_channels = n_channels\n",
        "        self.weight = nn.Parameter(torch.rand(self.out_channels, self.n_channels, self.kernel_size[0] , self.kernel_size[1] ))\n",
        "        self.bias = nn.Parameter(torch.rand(self.out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = convAppx.apply(x, self.weight, self.bias, self.padding, self.stride)\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "9jIHr9-Vw36G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approximate Fully Connected Layer"
      ],
      "metadata": {
        "id": "3ZY9ZCOQxAKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class linear_appx(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, bias):\n",
        "        ctx.save_for_backward(input, weight, bias)\n",
        "\n",
        "        input = input.data.numpy()\n",
        "        weight = weight.data.numpy()\n",
        "        bias = bias.data.numpy()\n",
        "        def appx_mul(A,B):\n",
        "          window = np.zeros((A.shape[0],B.shape[1] ))\n",
        "          for k in range(A.shape[0]):\n",
        "            for l in range(B.shape[1]):\n",
        "              for j in range(A.shape[1]):\n",
        "                  window[k,l] +=  FP_appx_mul(A[k,j],B[j,l])\n",
        "          return window\n",
        "\n",
        "        #output = input.mm(weight.t()) + bias\n",
        "        output = appx_mul(input,np.transpose(weight)) + bias\n",
        "        return torch.from_numpy(output).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weight, bias = ctx.saved_tensors\n",
        "\n",
        "        grad_input = grad_output.mm(weight.float())\n",
        "        grad_weight = grad_output.t().mm(input.float())\n",
        "        grad_bias = grad_output.sum(0)\n",
        "        return grad_input, grad_weight, grad_bias\n",
        "\n",
        "\n",
        "class MyLinear(nn.Module):\n",
        "    def __init__(self,in_features, out_features ):\n",
        "        super(MyLinear, self).__init__()\n",
        "        self.fn = linear_appx.apply\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bias = torch.nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fn(x, self.weight, self.bias)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DGDgYavtxEId"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approximate model"
      ],
      "metadata": {
        "id": "B5-P_sWMxQjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class appx_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(appx_model, self).__init__()\n",
        "        self.conv1 = MyConv2d(1, 32, 3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = MyConv2d(32, 64,3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d(2)\n",
        "        self.linear1 = MyLinear(7 * 7 * 64, 200)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.linear2 = MyLinear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(self.relu1(x))\n",
        "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        #x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "model_appx = appx_model()\n",
        "filename = \"trained_lenet5.pt\"\n",
        "\n",
        "model_appx.load_state_dict(torch.load(filename, map_location=torch.device('cpu') ))\n",
        "model_appx.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06STZmQWxgOZ",
        "outputId": "ec3805d0-f556-4358-8ecc-732dda21c53a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "appx_model(\n",
              "  (conv1): MyConv2d()\n",
              "  (relu1): ReLU(inplace=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): MyConv2d()\n",
              "  (relu2): ReLU(inplace=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (linear1): MyLinear()\n",
              "  (relu3): ReLU(inplace=True)\n",
              "  (linear2): MyLinear()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "x68X5xmCynKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i =  0\n",
        "x = data[i].unsqueeze(0)\n",
        "y = label[i].unsqueeze(0)\n",
        "\n",
        "scores_exact = model_appx(x)\n",
        "pred_exact = model_appx(x).data.max(1, keepdim=True)[1][0].item()\n",
        "print(\"Scores exact:\", scores_exact)\n",
        "print(\"Prediction exact:\", pred_exact)\n",
        "print(\"Label:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QYc6QhNyxBQ",
        "outputId": "3d26930a-b25a-45e6-ac64-2266ac6d417f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores exact: tensor([[-20.9173, -12.7048,   8.2331,  14.1789, -24.7654, -24.1655, -88.4965,\n",
            "          55.2600,  -2.4204,  12.6122]], grad_fn=<linear_appxBackward>)\n",
            "Prediction exact: 7\n",
            "Label: tensor([7])\n"
          ]
        }
      ]
    }
  ]
}